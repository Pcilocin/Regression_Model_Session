import pandas as pd
import joblib
import numpy as np
import optuna
import json
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import f1_score
from trading_tools import (
    prepare_master_dataframe,
    FeatureEngineSMC,
    LiquidityMLModel,
    START_DATE,
    TICKER,
    DOWNLOAD_DATA,
    LOOK_FORWARD,
    TRESHOLD_PCT
)
from Market_Scanner_Model_SHORT import find_significant_moves

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
MODEL_TYPE = 'SHORT'
N_TRIALS = 100  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –ø–æ–∏—Å–∫–∞. –ù–∞—á–Ω–∏—Ç–µ —Å 50, –¥–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –º–æ–∂–Ω–æ 100-200.


# --- –§–£–ù–ö–¶–ò–Ø –¶–ï–õ–ò –î–õ–Ø OPTUNA ---
def objective(trial, X, y):
    """
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —á—Ç–æ –º—ã —Ö–æ—Ç–∏–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å.
    –ú—ã –±—É–¥–µ–º –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å F1-score –¥–ª—è –∫–ª–∞—Å—Å–∞ 1 (—Å–∏–≥–Ω–∞–ª—ã –Ω–∞ –†–û–°–¢).
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    params = {
        'objective': 'binary',
        'metric': 'logloss',
        'random_state': 33,
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),
        'num_leaves': trial.suggest_int('num_leaves', 10, 70),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'subsample': trial.suggest_float('subsample', 0.8, 1.0, step=0.05),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0, step=0.05),
        'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 10.0, log=True),
        'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 10.0, log=True),
        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1.0, 10.0)  # Optuna —Å–∞–º–∞ –ø–æ–¥–±–µ—Ä–µ—Ç –≤–µ—Å
    }

    model = LiquidityMLModel(params=params)

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º TimeSeriesSplit –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    tscv = TimeSeriesSplit(n_splits=7)
    scores = []

    for train_index, val_index in tscv.split(X):
        X_train, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train, y_val = y.iloc[train_index], y.iloc[val_index]

        model.train(X_train, y_train)
        preds = model.model.predict(X_val)

        # –ù–∞—à–∞ –≥–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å - F1 score –¥–ª—è –∫–ª–∞—Å—Å–∞ 1 (Up moves)
        score = f1_score(y_val, preds, average='macro', zero_division=0)
        scores.append(score)

    return np.mean(scores)


# --- –û–°–ù–û–í–ù–û–ô –ë–õ–û–ö ---
if __name__ == "__main__":
    print("--- –≠–¢–ê–ü 1: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –¢–Æ–ù–ò–ù–ì–ê ---")
    raw_final_df, df_4h, df_30m, df_15m, df_5m, df_1m = prepare_master_dataframe(START_DATE, TICKER, DOWNLOAD_DATA)
    feature_engine = FeatureEngineSMC(
        main_df_1h=raw_final_df, ltf_df_4h=df_4h, ltf_df_30m=df_30m,
        ltf_df_15m=df_15m, ltf_df_5m=df_5m, ltf_df_1m=df_1m
    )
    X, _, _, enriched_df = feature_engine.run(model_type=MODEL_TYPE, create_target=False)
    y = find_significant_moves(enriched_df, look_forward=LOOK_FORWARD, threshold_pct=TRESHOLD_PCT)

    # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤ —Ç—Ä–µ–π–Ω–µ—Ä–µ
    data_for_training = X.copy()
    data_for_training['target'] = y
    data_for_training = data_for_training[data_for_training['target'] != 0]
    X_filtered = data_for_training.drop(columns=['target'])
    y_binary = data_for_training['target'].replace({-1: 0})

    print(f"\n--- –≠–¢–ê–ü 2: –ó–ê–ü–£–°–ö OPTUNA –î–õ–Ø –ü–û–ò–°–ö–ê –õ–£–ß–®–ò–• –ü–ê–†–ê–ú–ï–¢–†–û–í ({N_TRIALS} –ø–æ–ø—ã—Ç–æ–∫) ---")
    study = optuna.create_study(direction='maximize')  # –ú—ã –ú–ê–ö–°–ò–ú–ò–ó–ò–†–£–ï–ú F1-score
    study.optimize(lambda trial: objective(trial, X_filtered, y_binary), n_trials=N_TRIALS)

    print("\n‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("üî• –õ—É—á—à–∏–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞–π–¥–µ–Ω—ã:", study.best_params)
    print(f"üèÜ –õ—É—á—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ F1-score (class 1): {study.best_value:.4f}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Ñ–∞–π–ª
    safe_ticker = TICKER.replace('/', '_')
    params_filename = f"best_params_{MODEL_TYPE}_{safe_ticker}.json"
    with open(params_filename, 'w') as f:
        json.dump(study.best_params, f, indent=4)
    print(f"üíæ –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {params_filename}")