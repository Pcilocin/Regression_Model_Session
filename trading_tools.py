
# trading_tools.py - –ù–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö –±–æ—Ç–æ–≤

# --- –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï –ò–ú–ü–û–†–¢–´ –î–õ–Ø –ò–ù–°–¢–†–£–ú–ï–ù–¢–û–í ---
import pandas as pd
import pandas_ta as ta
import numpy as np
import ccxt
import lightgbm as lgb
import joblib
import requests
from sklearn.metrics import classification_report, mean_absolute_error, mean_squared_error
import optuna
import time
import os
import logging
from scipy.signal import argrelextrema


LOOK_FORWARD_PERIOD = 8 # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞—Å–æ–≤ –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è —Ü–µ–Ω—ã
# ATR_MULTIPLIER_PERIOD = 2.0 # –ö–æ–ª–µ–±–∞–Ω–∏—è —Ü–µ–Ω—ã  ATR
START_DATE = '2024-01-01'
initial_capital = 100
TICKER = 'SUI/USDT'
safe_ticker = TICKER.replace('/', '_')
DOWNLOAD_DATA = False # True –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö / False –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞


class DataHandler:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å "—É–º–Ω—ã–º" –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –ø–æ–ª–Ω–æ–π –∑–∞—â–∏—Ç–æ–π.
    (–í–µ—Ä—Å–∏—è 3.2 - —Å –∞—Ç–æ–º–∞—Ä–Ω–æ–π –∑–∞–ø–∏—Å—å—é, –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏)
    """

    def __init__(self, symbol: str, timeframe: str, start_date: str):
        self.symbol = symbol
        self.timeframe = timeframe
        self.start_date = start_date
        self.exchange = ccxt.bybit({'options': {'defaultType': 'swap', 'defaultSubType': 'linear'}})
        self.safe_symbol = symbol.replace('/', '_')
        self.cache_dir = "data_cache"
        self.cache_filepath = os.path.join(
            self.cache_dir,
            f"{self.safe_symbol}_{self.timeframe}_{self.start_date.split('T')[0]}.parquet"
        )
        os.makedirs(self.cache_dir, exist_ok=True)

    def _download_data(self, since_timestamp):
        """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –¥–∞—Ç—ã."""
        all_ohlcv = []
        limit = 1000
        since = since_timestamp

        while True:
            try:
                ohlcv = self.exchange.fetch_ohlcv(self.symbol, self.timeframe, since, limit)
                if len(ohlcv):
                    if len(all_ohlcv) > 0 and ohlcv[0][0] == all_ohlcv[-1][0]:
                        ohlcv = ohlcv[1:]
                    if not ohlcv: break

                    since = ohlcv[-1][0] + (self.exchange.parse_timeframe(self.timeframe) * 1000)
                    all_ohlcv.extend(ohlcv)
                    logging.info(f"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞: {len(all_ohlcv)} —Å–≤–µ—á–µ–π...")
                    if len(ohlcv) < limit: break
                else:
                    break
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö: {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 10 —Å–µ–∫—É–Ω–¥...")
                time.sleep(10)

        return all_ohlcv

    def _validate_and_save(self, df_to_save: pd.DataFrame, old_df: pd.DataFrame = None):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ –∞—Ç–æ–º–∞—Ä–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –≤ –∫—ç—à."""
        # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è: –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ high >= low –≤–æ –≤—Å–µ–º DataFrame
        if not (df_to_save['high'] >= df_to_save['low']).all():
            logging.error("‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å–≤–µ—á–∏ (high < low). –ö—ç—à –Ω–µ –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω.")
            return old_df if old_df is not None else pd.DataFrame()  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ

        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∏ (gaps)
        time_diffs = df_to_save.index.to_series().diff().dropna()
        expected_interval = pd.Timedelta(self.timeframe)
        if (time_diffs > expected_interval * 1.5).any():  # –î–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –¥–æ–ø—É—Å–∫ –≤ 50%
            logging.warning("‚ö†Ô∏è –í –¥–∞–Ω–Ω—ã—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–ø—É—Å–∫–∏ (gaps)! –ö—ç—à –≤—Å–µ —Ä–∞–≤–Ω–æ –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω.")

        # 3. –ê—Ç–æ–º–∞—Ä–Ω–∞—è –∑–∞–ø–∏—Å—å –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π
        try:
            temp_filepath = self.cache_filepath + ".tmp"
            df_to_save.to_parquet(temp_filepath)
            os.replace(temp_filepath, self.cache_filepath)
            logging.info(f"üíæ –ö—ç—à —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω/–æ–±–Ω–æ–≤–ª–µ–Ω: {self.cache_filepath}")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫—ç—à–∞: {e}. –§–∞–π–ª –Ω–µ –±—ã–ª –∏–∑–º–µ–Ω–µ–Ω.")
            if os.path.exists(temp_filepath):
                os.remove(temp_filepath)  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            return old_df if old_df is not None else pd.DataFrame()

        return df_to_save

    def fetch_data(self, update_cache: bool = None) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É—è "—É–º–Ω—ã–π" –∫—ç—à.

        Args:
            update_cache (bool): –ï—Å–ª–∏ True, –¥–æ–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.
                                 –ï—Å–ª–∏ False, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫—ç—à.
        """
        if update_cache is None:
            update_cache = DOWNLOAD_DATA

        if os.path.exists(self.cache_filepath):
            logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –∫—ç—à! –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞: {self.cache_filepath}")
            try:
                cached_df = pd.read_parquet(self.cache_filepath).copy()
            except Exception as e:
                logging.error(f"‚ùå –ö—ç—à-—Ñ–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω: {e}. –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫—É.")
                os.remove(self.cache_filepath)
                return self.fetch_data()

            if not update_cache:
                logging.info("üîå –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ –æ—Ç–∫–ª—é—á–µ–Ω–æ. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞.")
                return cached_df

            last_timestamp_ms = int(cached_df.index[-1].timestamp() * 1000)
            logging.info(f"–ü–æ—Å–ª–µ–¥–Ω—è—è —Å–≤–µ—á–∞ –≤ –∫—ç—à–µ: {cached_df.index[-1]}. –î–æ–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ...")

            new_ohlcv = self._download_data(since_timestamp=last_timestamp_ms)

            if not new_ohlcv:
                logging.info("–ù–æ–≤—ã—Ö —Å–≤–µ—á–µ–π –Ω–µ—Ç. –î–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã.")
                return cached_df

            new_df = pd.DataFrame(new_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            new_df['timestamp'] = pd.to_datetime(new_df['timestamp'], unit='ms')
            new_df.set_index('timestamp', inplace=True)

            combined_df = pd.concat([cached_df, new_df])
            combined_df = combined_df[~combined_df.index.duplicated(keep='last')]

            logging.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_df)} –Ω–æ–≤—ã—Ö —Å–≤–µ—á–µ–π. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞...")
            return self._validate_and_save(combined_df, old_df=cached_df)

        else:  # –ï—Å–ª–∏ –∫—ç—à–∞ –Ω–µ—Ç, —Ç–æ –ø—Ä–æ—Å—Ç–æ —Å–∫–∞—á–∏–≤–∞–µ–º –≤—Å—ë
            logging.info(f"–ö—ç—à –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–ª–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö {self.symbol} —Å {self.start_date} —Å –±–∏—Ä–∂–∏...")
            date_string = self.start_date
            if ' ' not in date_string and 'T' not in date_string:
                date_string += 'T00:00:00Z'
            start_timestamp_ms = self.exchange.parse8601(date_string)

            all_ohlcv = self._download_data(since_timestamp=start_timestamp_ms)

            if not all_ohlcv:
                logging.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.")
                return pd.DataFrame()

            df = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df.set_index('timestamp', inplace=True)
            df = df[~df.index.duplicated(keep='first')]

            return self._validate_and_save(df)

# --------------------------<–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–æ–º–∏–Ω–∞—Ü–∏–∏ –±–∏—Ç–∫–æ–∏–Ω–∞>----------------------------------------

    #
    #     # 3. –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π (–∫–∞–∫ –≤ DataHandler)
    #     while True:
    #         ohlcv = binance.fetch_ohlcv('BTCDOMUSDT', '1h', since, limit)
    #         if len(ohlcv):
    #             since = ohlcv[-1][0] + (binance.parse_timeframe('1h') * 1000)
    #             all_ohlcv.extend(ohlcv)
    #             if len(ohlcv) < limit:
    #                 break
    #         else:
    #             break
    #
    #     # 4. –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
    #     if all_ohlcv:
    #         df_dom = pd.DataFrame(all_ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    #         df_dom['timestamp'] = pd.to_datetime(df_dom['timestamp'], unit='ms')
    #         df_dom.set_index('timestamp', inplace=True)
    #         df_dom = df_dom[['close']].rename(columns={'close': 'btc_dominance'})
    #         print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –¥–æ–º–∏–Ω–∞—Ü–∏–∏ BTC —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω. –ó–∞–ø–∏—Å–µ–π: {len(df_dom)}")
    #     else:
    #         print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å –¥–æ–º–∏–Ω–∞—Ü–∏–∏ BTC (–¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã).")
    #
    # except Exception as e:
    #     print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–º–∏–Ω–∞—Ü–∏–∏ BTC: {e}")

# --------------------------</–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –¥–æ–º–∏–Ω–∞—Ü–∏–∏ –±–∏—Ç–∫–æ–∏–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞>----------------------------------------

# ---------------------< –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• >------------------------
def prepare_master_dataframe(start_date, ticker, download_data):
    # ----------------< –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö >-----------------------
    print("--- –≠–¢–ê–ü 1: –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ---")

    data_handler_1m = DataHandler(symbol=TICKER, timeframe='1m', start_date=START_DATE)
    df_1m = data_handler_1m.fetch_data(update_cache=DOWNLOAD_DATA).copy()
    if not df_1m.empty: df_1m = df_1m.reset_index().set_index('timestamp')

    data_handler_5m = DataHandler(symbol=TICKER, timeframe='5m', start_date=START_DATE)
    df_5m = data_handler_5m.fetch_data(update_cache=DOWNLOAD_DATA).copy()
    if not df_5m.empty: df_5m = df_5m.reset_index().set_index('timestamp')

    data_handler_15m = DataHandler(symbol=TICKER, timeframe='15m', start_date=START_DATE)
    df_15m = data_handler_15m.fetch_data(update_cache=DOWNLOAD_DATA).copy()
    if not df_15m.empty: df_15m = df_15m.reset_index().set_index('timestamp')

    data_handler_30m = DataHandler(symbol=TICKER, timeframe='30m', start_date=START_DATE)
    df_30m = data_handler_30m.fetch_data(update_cache=DOWNLOAD_DATA).copy()
    if not df_30m.empty: df_30m = df_30m.reset_index().set_index('timestamp')

    data_handler_1h = DataHandler(symbol=TICKER, timeframe='1h', start_date=START_DATE)
    df_1h = data_handler_1h.fetch_data(update_cache=DOWNLOAD_DATA).copy()
    if not df_1h.empty: df_1h = df_1h.reset_index().set_index('timestamp')

    data_handler_4h = DataHandler(symbol=TICKER, timeframe='4h', start_date=START_DATE)
    df_4h = data_handler_4h.fetch_data(update_cache=DOWNLOAD_DATA).copy()
    if not df_4h.empty: df_4h = df_4h.reset_index().set_index('timestamp')

    data_handler_1d = DataHandler(symbol=TICKER, timeframe='1d', start_date=START_DATE)
    df_1d = data_handler_1d.fetch_data(update_cache=DOWNLOAD_DATA).copy()
    if not df_1d.empty: df_1d = df_1d.reset_index().set_index('timestamp')

    if df_1d.empty or df_1h.empty or df_4h.empty or df_30m.empty or df_15m.empty or df_5m.empty or df_1m.empty:
        print("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–¥–∏–Ω –∏–∑ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤. –°–∫—Ä–∏–ø—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ DataFrame'—ã, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–∞–¥–µ–Ω–∏—è
        return pd.DataFrame(), pd.DataFrame(), pd.DataFrame()

    df_fng = fetch_fear_and_greed_index(limit=0)
    # ----------------</ –≠—Ç–∞–ø 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞>-----------------------


    df_poc_h = calculate_poc_from_ltf(df_1h, df_1m, period='H')
    df_poc_4h = calculate_poc_from_ltf(df_4h, df_5m, period='4H')
    df_poc_d = calculate_poc_from_ltf(df_1d, df_5m, period='D')
    #

    # 3. –†–∞—Å—á–µ—Ç HTF –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    features_4h = pd.DataFrame(index=df_4h.index)
    features_4h['ema_50_4h'] = df_4h.ta.ema(length=50)
    adx_4h = df_4h.ta.adx(length=14)
    if adx_4h is not None and 'ADX_14' in adx_4h.columns:
        features_4h['adx_14_4h'] = adx_4h['ADX_14']
    features_4h['atr_14_4h'] = df_4h.ta.atr(length=14)  # –í–∞–∂–Ω–æ –¥–ª—è trend_strength

    # 4. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤ final_df (–º–∞—Å—Ç–µ—Ä-—Ñ—Ä–µ–π–º 1H)
    final_df = df_1h.copy()
    final_df = pd.merge_asof(final_df, features_4h, left_index=True, right_index=True, direction='backward')
    if not df_fng.empty:
        final_df = pd.merge_asof(final_df, df_fng.rename(columns={'value': 'fear_greed_value'}), left_index=True,
                                 right_index=True, direction='backward')
    if not df_poc_h.empty:
        final_df = final_df.join(df_poc_h)
    if not df_poc_4h.empty:
        final_df = pd.merge_asof(final_df, df_poc_4h, left_index=True, right_index=True, direction='backward')
    if not df_poc_d.empty:
        final_df = pd.merge_asof(final_df, df_poc_d, left_index=True, right_index=True, direction='backward')

    final_df.fillna(method='ffill', inplace=True)
    final_df.dropna(inplace=True)

    print("‚úÖ –ú–∞—Å—Ç–µ—Ä-DataFrame –∏ LTF –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã.")
    return final_df, df_30m, df_15m, df_5m, df_1m

    # ==============================================================
    # features_4h = pd.DataFrame(index=df_4h.index)
    # # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º EMA (–∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ)
    # features_4h['ema_50_4h'] = df_4h.ta.ema(length=50, append=False)
    # # –î–û–ë–ê–í–õ–Ø–ï–ú –†–ê–°–ß–ï–¢ ADX –ù–ê 4–ß –¢–§
    # adx_4h = df_4h.ta.adx(length=14, append=False)
    # # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º ADX –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
    # if adx_4h is not None and 'ADX_14' in adx_4h.columns:
    #     features_4h['adx_14_4h'] = adx_4h['ADX_14']
    #
    #
    # features_1d = df_1d.ta.ema(length=21, append=False).to_frame(name='ema_21_1d').copy()
    # if not features_4h.empty: features_4h = features_4h.reset_index().set_index('timestamp')
    # if not features_1d.empty: features_1d = features_1d.reset_index().set_index('timestamp')
    #
    # final_df = df_1h.copy()
    # final_df = pd.merge_asof(left=final_df, right=features_4h, left_index=True, right_index=True, direction='backward')
    # final_df = pd.merge_asof(left=final_df, right=features_1d, left_index=True, right_index=True, direction='backward')
    # if not df_fng.empty:
    #     final_df = pd.merge_asof(left=final_df, right=df_fng, left_index=True, right_index=True, direction='backward')
    #     final_df.rename(columns={'value': 'fear_greed_value'}, inplace=True)
    # if not df_poc_h.empty: final_df = final_df.join(df_poc_h)
    # if not df_poc_4h.empty: final_df = pd.merge_asof(left=final_df, right=df_poc_4h, left_index=True, right_index=True,
    #                                                  direction='backward')
    # if not df_poc_d.empty: final_df = pd.merge_asof(left=final_df, right=df_poc_d, left_index=True, right_index=True,
    #                                                 direction='backward')
    #
    # final_df.fillna(method='ffill', inplace=True)
    # final_df.dropna(inplace=True)
    # print("‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ —É—Å–ø–µ—à–Ω–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã.")

    # return final_df, df_5m, df_1m

# ---------------------</ –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –ó–ê–í–ï–†–®–ï–ù–ê>------------------------

# ---------------------<–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏>------------------------

def fetch_fear_and_greed_index(limit=0, retries=3, delay=5, timeout=10):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –ò–Ω–¥–µ–∫—Å–∞ —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏ —Å –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫.
    """
    print("‚û°Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ò–Ω–¥–µ–∫—Å–∞ —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏...")

    for attempt in range(retries):
        try:
            # --- ‚úÖ –ò–ó–ú–ï–ù–ï–ù–ò–ï: –î–æ–±–∞–≤–ª–µ–Ω —Ç–∞–π–º–∞—É—Ç –≤ 10 —Å–µ–∫—É–Ω–¥ ---
            response = requests.get(
                f"https://api.alternative.me/fng/?limit={limit}&format=json",
                timeout=timeout
            )
            response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏ HTTP (4xx, 5xx)
            data = response.json()['data']

            df = pd.DataFrame(data)
            df['value'] = pd.to_numeric(df['value'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
            df = df.iloc[::-1].reset_index(drop=True)
            df.set_index('timestamp', inplace=True)

            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –ò–Ω–¥–µ–∫—Å–∞.")
            return df[['value']]

        except requests.exceptions.RequestException as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retries}): {e}")
            if attempt < retries - 1:
                print(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {delay} —Å–µ–∫—É–Ω–¥...")
                time.sleep(delay)
            else:
                print("‚ùå –ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫. –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ.")
                return pd.DataFrame()  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame –ø–æ—Å–ª–µ –≤—Å–µ—Ö –Ω–µ—É–¥–∞—á


# ---------------------</–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–∞ —Å—Ç—Ä–∞—Ö–∞ –∏ –∂–∞–¥–Ω–æ—Å—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞>------------------------



class LiquidityMLModel:
    def __init__(self, params=None):
        if params is None:
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            params = {
                'objective': 'binary',
                'n_estimators': 200,
                'learning_rate': 0.05,
                'num_leaves': 31
            }

        # ### –ì–õ–ê–í–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è 100% –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ ###
        params['random_state'] = 33
        params['deterministic'] = True # <--- –°–∞–º—ã–π –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä

        self.model = lgb.LGBMClassifier(**params)

    def train(self, X_train, y_train):
        print("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ LightGBM...")
        self.model.fit(X_train, y_train)
        print("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")

    def predict(self, X_test):
        return self.model.predict(X_test)

    def predict_proba(self, X_test):
        return self.model.predict_proba(X_test)

    def evaluate(self, X_test, y_test):
        predictions = self.predict(X_test)
        print("\n--- –û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ (2 –∫–ª–∞—Å—Å–∞: 0-–ù–µ—Ç, 1-–î–∞) ---")  # <-- –¢–µ–∫—Å—Ç
        print(classification_report(y_test, predictions, labels=[0, 1], zero_division=0))  # <-- labels

    def get_feature_importance(self):
        return pd.DataFrame({
            'feature': self.model.feature_name_,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)

    def save_model(self, filepath=f"Long-only_model_V6_{safe_ticker}.pkl"):
        joblib.dump(self.model, filepath)
        print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filepath}")

    def load_model(self, filepath=f"Long-only_model_V6_{safe_ticker}.pkl"):
        self.model = joblib.load(filepath)
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {filepath}")


class LiquidityMLRegressor:
    """–ù–û–í–´–ô –ö–õ–ê–°–° –¥–ª—è LightGBM –†–µ–≥—Ä–µ—Å—Å–æ—Ä–∞."""

    def __init__(self, params=None):
        if params is None:
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
            params = {'objective': 'regression_l1', 'metric': 'mae', 'random_state': 33, 'n_jobs': -1}
        self.model = lgb.LGBMRegressor(**params)

    def train(self, X_train, y_train):
        self.model.fit(X_train, y_train)

    def predict(self, X_test):
        return self.model.predict(X_test)

    def evaluate(self, X_test, y_test):
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å."""
        predictions = self.predict(X_test)
        mae = mean_absolute_error(y_test, predictions)
        rmse = np.sqrt(mean_squared_error(y_test, predictions))

        # –†–∞—Å—á–µ—Ç "–¢–æ—á–Ω–æ—Å—Ç–∏ 85%"
        # |–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ - –†–µ–∞–ª—å–Ω–æ—Å—Ç—å| < 0.15 * –†–µ–∞–ª—å–Ω–æ—Å—Ç—å
        # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å, –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ = 0
        relative_error = np.abs((predictions - y_test) / y_test.replace(0, 1e-9))
        accuracy_85 = np.mean(relative_error < 0.15) * 100

        print("\n--- –û—Ç—á–µ—Ç –æ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ ---")
        print(f"–°—Ä–µ–¥–Ω—è—è –ê–±—Å–æ–ª—é—Ç–Ω–∞—è –û—à–∏–±–∫–∞ (MAE): {mae:.4f}")
        print(f"  -> –í —Å—Ä–µ–¥–Ω–µ–º –º–æ–¥–µ–ª—å –æ—à–∏–±–∞–µ—Ç—Å—è –Ω–∞ —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ (–≤ R).")
        print(f"–ö–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä. –∫–≤–∞–¥—Ä. –æ—à–∏–±–∫–∏ (RMSE): {rmse:.4f}")
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å (–æ—à–∏–±–∫–∞ < 15%): {accuracy_85:.2f}%")
        print("---------------------------\n")
        return pd.DataFrame({'y_true': y_test, 'y_pred': predictions})

    def save_model(self, filepath):
        joblib.dump(self.model, filepath)
        print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filepath}")

    def load_model(self, filepath):
        self.model = joblib.load(filepath)
        print(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {filepath}")



# -------------------------< /–ù–æ–≤–∞—è –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ POC >----------------------------------

def calculate_poc_from_ltf(df_high_tf: pd.DataFrame, df_low_tf: pd.DataFrame, period: str = 'H') -> pd.DataFrame:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Point of Control (POC) –¥–ª—è —Å—Ç–∞—Ä—à–µ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ (high_tf),
    –∏—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—ã–µ –º–ª–∞–¥—à–µ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ (low_tf) –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ–±—ä–µ–º–∞.

    Args:
        df_high_tf: DataFrame —Å–æ —Å—Ç–∞—Ä—à–∏–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1H).
        df_low_tf: DataFrame —Å –º–ª–∞–¥—à–∏–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 5m).
        period: –ü–µ—Ä–∏–æ–¥ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ ('H' –¥–ª—è —á–∞—Å–∞, 'D' –¥–ª—è –¥–Ω—è).

    Returns:
        DataFrame —Å –∏–Ω–¥–µ–∫—Å–æ–º –æ—Ç —Å—Ç–∞—Ä—à–µ–≥–æ –¢–§ –∏ –∫–æ–ª–æ–Ω–∫–æ–π POC.
    """
    print(f"‚û°Ô∏è –†–∞—Å—á–µ—Ç POC –∑–∞ –ø–µ—Ä–∏–æ–¥ '{period}' –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –º–ª–∞–¥—à–µ–≥–æ –¢–§...")

    if df_low_tf.empty:
        print("‚ö†Ô∏è DataFrame –º–ª–∞–¥—à–µ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ –ø—É—Å—Ç. –†–∞—Å—á–µ—Ç POC –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
        return pd.DataFrame(index=df_high_tf.index, columns=[f'poc_{period.lower()}'])

    # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –†–∞–±–æ—Ç–∞–µ–º —Å –∫–æ–ø–∏–µ–π, —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–π DataFrame ---
    ltf_copy = df_low_tf.copy()

    median_price = ltf_copy['close'].median()
    if median_price > 1000:
        tick_size = 0.5
    elif median_price > 100:
        tick_size = 0.1
    elif median_price > 1:
        tick_size = 0.01
    else:
        tick_size = 0.0001

    ltf_copy['price_bin'] = (ltf_copy['close'] / tick_size).round() * tick_size
    ltf_copy['time_group'] = ltf_copy.index.floor(period)

    volume_profile = ltf_copy.groupby(['time_group', 'price_bin'])['volume'].sum()
    poc_series = volume_profile.groupby('time_group').idxmax().apply(lambda x: x[1])
    poc_df = poc_series.to_frame(name=f'poc_{period.lower()}')

    # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2 (–ö–õ–Æ–ß–ï–í–û–ï): –°–¥–≤–∏–≥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ 1 —à–∞–≥ –≤ –±—É–¥—É—â–µ–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å lookahead bias ---
    # POC –∑–∞ 10:00-10:59 –±—É–¥–µ—Ç –ø—Ä–∏—Å–≤–æ–µ–Ω —Å–≤–µ—á–µ 11:00
    poc_df_shifted = poc_df.shift(1)

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å df_high_tf
    final_poc_df = df_high_tf.join(poc_df_shifted)
    final_poc_df[f'poc_{period.lower()}'].ffill(inplace=True)

    print("‚úÖ –†–∞—Å—á–µ—Ç POC –∑–∞–≤–µ—Ä—à–µ–Ω.")
    return final_poc_df[[f'poc_{period.lower()}']]


# -------------------------< /–ù–æ–≤–∞—è –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ POC >----------------------------------

# ==============================================================================
# –†–ê–ó–î–ï–õ 2: –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–ô FEATURE ENGINE (SMC) (–í–µ—Ä—Å–∏—è 4.0)
# ==============================================================================

class FeatureEngineSMC:
    """
    –ï–¥–∏–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (LONG –∏ SHORT) —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º,
    –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∞–Ω–∞–ª–∏–∑–∞ –º–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä—ã LTF.
    """
    def __init__(self, main_df_1h: pd.DataFrame, ltf_df_1m: pd.DataFrame = None, ltf_df_5m: pd.DataFrame = None, ltf_df_15m: pd.DataFrame = None, ltf_df_30m: pd.DataFrame = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ç–æ—Ä.
        Args:
            main_df_1h: –û—Å–Ω–æ–≤–Ω–æ–π DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1H), –∫–æ—Ç–æ—Ä—ã–π —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç POC, HTF —Ñ–∏—á–∏ –∏ —Ç.–¥.
            ltf_df_1m: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π DataFrame —Å 1-–º–∏–Ω—É—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–π–±–ª–æ–≤.
        """
        self.df = main_df_1h.copy()
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º 1M –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –æ–Ω–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã. –û–Ω–∏ –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –¥–ª—è —Ç–≤–æ–µ–π –Ω–æ–≤–æ–π –ª–æ–≥–∏–∫–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ç–∞—Ä–≥–µ—Ç–æ–≤.
        self.df_1m = ltf_df_1m.copy() if ltf_df_1m is not None else pd.DataFrame() # –°–æ—Ö—Ä–∞–Ω—è–µ–º 1m
        self.df_5m = ltf_df_5m.copy() if ltf_df_5m is not None else pd.DataFrame() # <-- –î–û–ë–ê–í–õ–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º 5m
        self.df_15m = ltf_df_15m.copy() if ltf_df_15m is not None else pd.DataFrame() # <-- –î–û–ë–ê–í–õ–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º 15m
        self.df_30m = ltf_df_30m.copy() if ltf_df_30m is not None else pd.DataFrame() # <-- –î–û–ë–ê–í–õ–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º 30m



        self.liquidity_map = []
        self.next_liquidity_id = 0
        self.liquidity_vector_features = []  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ .run()

        # --- –ù–ê–ß–ê–õ–û –ù–û–í–û–ì–û –ë–õ–û–ö–ê: –°–ü–ò–°–ö–ò –ü–†–ò–ó–ù–ê–ö–û–í ---


    STATIC_FEATURES_LONG = [
        'trend_strength_4h',
        'dist_to_static_pdl_atr',  # –ö–ª—é—á–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –ª–æ–Ω–≥–∞
        'bullish_rejection_power',  # –ö–ª—é—á–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –ª–æ–Ω–≥–∞
        # 'bearish_rejection_power',
        'volume_spike_ratio',
        'hour_sin', 'hour_cos', 'day_sin', 'day_cos',
        'is_asian_session', 'is_london_session', 'is_newyork_session',
        'is_asian_killzone', 'is_london_killzone', 'is_newyork_killzone',
        # –î–æ–±–∞–≤—å —Å—é–¥–∞ ADX, RSI, F&G –∏ —Ç.–¥., –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
    ]

    STATIC_FEATURES_SHORT = [
        # --- 1. –ö–û–ù–¢–ï–ö–°–¢ –°–¢–ê–†–®–ï–ì–û –¢–§ ---
        'trend_strength_4h',  # –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ (–º—ã –≤—ã—à–µ/–Ω–∏–∂–µ 4H EMA?)
        'structure_state',  # –ù–∞—à 1H BOS/CHoCH –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä (–º—ã –≤ 1H –∞–ø- –∏–ª–∏ –¥–∞—É–Ω-—Ç—Ä–µ–Ω–¥–µ?)
        # --- 2. VSA-–ö–û–ù–¢–ï–ö–°–¢ (–≤—Å–µ –µ—â–µ –ø–æ–ª–µ–∑–µ–Ω) ---
        'dynamic_vol_ratio',  # VSA-–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ (–Ω–∞—à 1M Vol Ratio)
        'volume_spike_ratio',  # –í—Å–ø–ª–µ—Å–∫ 1H –æ–±—ä–µ–º–∞
        # --- 3. –ö–û–ù–¢–ï–ö–°–¢ –õ–ò–ö–í–ò–î–ù–û–°–¢–ò ---
        'dist_to_static_pdh_atr',  # –û–°–¢–ê–í–õ–Ø–ï–ú. (–ü–æ–ª–µ–∑–Ω–æ –∑–Ω–∞—Ç—å, –µ—Å–ª–∏ Asia High == PDH)
        'dist_to_static_pdl_atr',  # –û–°–¢–ê–í–õ–Ø–ï–ú. (–ö–æ–Ω—Ç–µ–∫—Å—Ç)
        # --- 4. –ö–û–ù–¢–ï–ö–°–¢ –°–í–ï–ß–ò ---
        'bearish_rejection_power',  # –§–æ—Ä–º–∞ 1–ß —Å–≤–µ—á–∏ (–≤–∞–∂–Ω–æ –¥–ª—è sweep)
        # --- 5. –ö–õ–Æ–ß–ï–í–´–ï –ü–†–ò–ó–ù–ê–ö–ò –î–õ–Ø –≠–¢–û–ô –ó–ê–î–ê–ß–ò ---
        'is_asian_session', 'is_london_session', 'is_newyork_session',
        'is_asian_killzone', 'is_london_killzone', 'is_newyork_killzone'
    ]
    # STATIC_FEATURES_SHORT = [
    #         'trend_strength_4h',
    #         'dist_to_static_pdh_atr',
    #         'bearish_rejection_power',
    #         'volume_spike_ratio',
    #         'hour_sin', 'hour_cos', #'day_sin', 'day_cos',
    #         # 'is_asian_session', 'is_london_session', 'is_newyork_session',
    #         # 'is_asian_killzone', 'is_london_killzone', 'is_newyork_killzone',
    #         # 'dist_to_static_bear_fvg_atr',
    #         # 'adx', 'dmp', 'dmn', 'dmp_dmn_diff', 'adx_atr_product',
    #         'dynamic_leg_vol',  # <-- –∏–∑ –®–∞–≥–∞ 2
    #         'dynamic_candle_vol',  # <-- –∏–∑ –®–∞–≥–∞ 2
    #         'dynamic_vol_ratio',  # <-- –∏–∑ –®–∞–≥–∞ 2
    #         'structure_state'
    #     ]

    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ç—ã —Ä–µ—à–∏–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:

    #             'is_compression', 'bullish_rejection_power', 'dist_to_static_pdh_atr',
    #             'dmp_dmn_diff', 'price_vs_ema200_1h_ratio', 'adx_atr_product',
    #             'dist_to_static_bear_fvg_atr', #'dist_to_static_bull_fvg_atr'
    #             'rsi_14_1h', 'dist_to_vwap_atr', 'fear_greed_change_3d' –∏ —Ç.–¥.

    # --- –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –ë–õ–û–ö–ê ---

    # --- –ü—Ä–∏–≤–∞—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã –ö–∞—Ä—Ç—ã –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (–∏–¥–µ–Ω—Ç–∏—á–Ω—ã –¥–ª—è LONG –∏ SHORT) ---

    def _add_liquidity_zone(self, zone_type, price_start, price_end=None):
        new_zone = {'id': self.next_liquidity_id, 'type': zone_type, 'price_start': price_start,
                    'price_end': price_end if price_end is not None else price_start, 'status': 'active'}
        self.liquidity_map.append(new_zone)
        self.next_liquidity_id += 1

    def _update_liquidity_status(self, current_high, current_low):
        for zone in self.liquidity_map:
            if zone['status'] == 'active':
                if not (current_high < zone['price_start'] or current_low > zone['price_end']):
                    zone['status'] = 'swept'

    def _precalculate_swing_points(self, fractal_order=5): #—Ä–∞—Å—á–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —Ç–æ—á–µ–∫
        """
        –ù–∞—Ö–æ–¥–∏—Ç –í–°–ï —Ñ—Ä–∞–∫—Ç–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã –∏ –º–∞–∫—Å–∏–º—É–º—ã –≤ 1H –¥–∞–Ω–Ω—ã—Ö (self.df)
        –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞.
        fractal_order = 5 –æ–∑–Ω–∞—á–∞–µ—Ç –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π 5-—Å–≤–µ—á–Ω–æ–π —Ñ—Ä–∞–∫—Ç–∞–ª (—Å–≤–µ—á–∞ –Ω–∏–∂–µ/–≤—ã—à–µ 2—Ö —Å–ª–µ–≤–∞ –∏ 2—Ö —Å–ø—Ä–∞–≤–∞)
        """
        print(f"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö —Ç–æ—á–µ–∫ (—Ñ—Ä–∞–∫—Ç–∞–ª {fractal_order})...")

        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã (–Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫) –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–æ–≤
        low_indices = argrelextrema(self.df['low'].values, np.less_equal, order=fractal_order)[0]
        # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –º–∞–∫—Å–∏–º—É–º–æ–≤
        high_indices = argrelextrema(self.df['high'].values, np.greater_equal, order=fractal_order)[0]

        # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (timestamps) —ç—Ç–∏—Ö —Å–≤–µ—á–µ–π
        self.all_swing_low_timestamps = self.df.iloc[low_indices].index
        self.all_swing_high_timestamps = self.df.iloc[high_indices].index

        print(
            f"–ù–∞–π–¥–µ–Ω–æ {len(self.all_swing_low_timestamps)} —Å–≤–∏–Ω–≥–æ–≤ (low) –∏ {len(self.all_swing_high_timestamps)} —Å–≤–∏–Ω–≥–æ–≤ (high).")

    # –í–°–¢–ê–í–¨ –≠–¢–û–¢ –ù–û–í–´–ô –ú–ï–¢–û–î –í–ù–£–¢–†–¨ –ö–õ–ê–°–°–ê FeatureEngineSMC


    def _find_significant_liquidity(self, rest_period_bars=24):
        """
        –ò–∑ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–≤–∏–Ω–≥–æ–≤ (high/low) –Ω–∞—Ö–æ–¥–∏—Ç —Ç–æ–ª—å–∫–æ "–∑–Ω–∞—á–∏–º—ã–µ",
        —Ç–æ –µ—Å—Ç—å —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ "–æ—Ç–¥—ã—Ö–∞–ª–∏" (–Ω–µ –±—ã–ª–∏ –ø—Ä–æ–±–∏—Ç—ã) N –±–∞—Ä–æ–≤ –ü–û–°–õ–ï –∏—Ö —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è.
        """
        print(f"–ü–æ–∏—Å–∫ –∑–Ω–∞—á–∏–º–æ–π '–æ—Ç–¥—ã—Ö–∞—é—â–µ–π' –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ (–ø–µ—Ä–∏–æ–¥ {rest_period_bars} –±–∞—Ä–∞)...")

        significant_highs_idx = []
        for high_ts in self.all_swing_high_timestamps:
            high_price = self.df.loc[high_ts, 'high']
            # –°–º–æ—Ç—Ä–∏–º –Ω–∞ N –±–∞—Ä–æ–≤ –ü–û–°–õ–ï —ç—Ç–æ–≥–æ —Ö–∞—è
            window_after = self.df.loc[high_ts:].iloc[1: 1 + rest_period_bars]
            if not window_after.empty:
                # –ï—Å–ª–∏ –ú–ê–ö–°–ò–ú–£–ú —ç—Ç–æ–≥–æ –æ–∫–Ω–∞ –≤—Å–µ —Ä–∞–≤–Ω–æ –ù–ò–ñ–ï –Ω–∞—à–µ–≥–æ —Ö–∞—è, –∑–Ω–∞—á–∏—Ç, —Ö–∞–π "—É–¥–µ—Ä–∂–∞–ª—Å—è"
                if window_after['high'].max() < high_price:
                    significant_highs_idx.append(high_ts)

        significant_lows_idx = []
        for low_ts in self.all_swing_low_timestamps:
            low_price = self.df.loc[low_ts, 'low']
            # –°–º–æ—Ç—Ä–∏–º –Ω–∞ N –±–∞—Ä–æ–≤ –ü–û–°–õ–ï —ç—Ç–æ–≥–æ –ª–æ—É
            window_after = self.df.loc[low_ts:].iloc[1: 1 + rest_period_bars]
            if not window_after.empty:
                # –ï—Å–ª–∏ –ú–ò–ù–ò–ú–£–ú —ç—Ç–æ–≥–æ –æ–∫–Ω–∞ –í–´–®–ï –Ω–∞—à–µ–≥–æ –ª–æ—É, –∑–Ω–∞—á–∏—Ç, –ª–æ—É "—É–¥–µ—Ä–∂–∞–ª—Å—è"
                if window_after['low'].min() > low_price:
                    significant_lows_idx.append(low_ts)

        self.significant_highs = pd.Series(self.df.loc[significant_highs_idx, 'high'])
        self.significant_lows = pd.Series(self.df.loc[significant_lows_idx, 'low'])

        print(f"–ù–∞–π–¥–µ–Ω–æ {len(self.significant_highs)} –∑–Ω–∞—á. –º–∞–∫—Å–∏–º—É–º–æ–≤ –∏ {len(self.significant_lows)} –∑–Ω–∞—á. –º–∏–Ω–∏–º—É–º–æ–≤.")


    def _calculate_market_structure(self): # –ø—Ä–æ–π—Ç–∏—Å—å –ø–æ –≤—Å–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–º —Ç–æ—á–∫–∞–º —Å–≤–∏–Ω–≥–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, –∫–æ–≥–¥–∞ —Ç—Ä–µ–Ω–¥ –±—ã—á–∏–π, –∞ –∫–æ–≥–¥–∞ –º–µ–¥–≤–µ–∂–∏–π.
        """
        –°–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫ 'structure_state' (+1 –¥–ª—è –±—ã—á—å–µ–≥–æ, -1 –¥–ª—è –º–µ–¥–≤–µ–∂—å–µ–≥–æ),
        –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ 1H Swing Highs/Lows.
        """
        print("–†–∞—Å—á–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä—ã–Ω–æ—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (BOS/CHoCH)...")

        # 1. –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç–æ—á–∫–∏ —Å–≤–∏–Ω–≥–æ–≤ –≤ –æ–¥–∏–Ω DataFrame
        lows = pd.DataFrame({'price': self.df.loc[self.all_swing_low_timestamps, 'low']},
                            index=self.all_swing_low_timestamps)
        lows['type'] = -1  # -1 = Swing Low

        highs = pd.DataFrame({'price': self.df.loc[self.all_swing_high_timestamps, 'high']},
                             index=self.all_swing_high_timestamps)
        highs['type'] = 1  # +1 = Swing High

        swing_events = pd.concat([lows, highs]).sort_index()

        if swing_events.empty:
            print("–í–ù–ò–ú–ê–ù–ò–ï: –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ—á–µ–∫ —Å–≤–∏–Ω–≥–∞, —Ä–∞—Å—á–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
            self.df['structure_state'] = 0  # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª–µ–º
            return

        # 2. –ò—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ —Å–æ–±—ã—Ç–∏—è–º –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥ (State Machine)
        structure_state = 0  # 0 = –ù–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω, +1 = –ë—ã—á–∏–π, -1 = –ú–µ–¥–≤–µ–∂–∏–π
        last_high = None
        last_low = None

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Ä–∏—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–±—ã—Å—Ç—Ä–µ–µ, —á–µ–º .loc –≤ —Ü–∏–∫–ª–µ)
        state_series = pd.Series(index=self.df.index, dtype='float64')

        for timestamp, event in swing_events.iterrows():
            if event['type'] == 1:  # –≠—Ç–æ Swing High
                if last_high is not None and event['price'] > last_high:
                    structure_state = 1  # Bullish BOS (Higher High)
                last_high = event['price']

            elif event['type'] == -1:  # –≠—Ç–æ Swing Low
                if last_low is not None and event['price'] < last_low:
                    structure_state = -1  # Bearish BOS / CHoCH (Lower Low)
                last_low = event['price']

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ –º–æ–º–µ–Ω—Ç —Å–æ–±—ã—Ç–∏—è
            state_series.loc[timestamp] = structure_state

        # 3. –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        # ffill() —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–±—ã—Ç–∏—è
        self.df['structure_state'] = state_series.ffill().fillna(0)  # ffill + fillna(0) –¥–ª—è —Å–∞–º–æ–≥–æ –Ω–∞—á–∞–ª–∞

    # –í–°–¢–ê–í–¨ –≠–¢–û–¢ –ù–û–í–´–ô –ú–ï–¢–û–î –í–ù–£–¢–†–¨ –ö–õ–ê–°–°–ê FeatureEngineSMC


    def _calculate_static_features(self):
        """ –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –Ω–µ-–∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ (–≤–µ–∫—Ç–æ—Ä–Ω—ã–µ) –ø—Ä–∏–∑–Ω–∞–∫–∏. """
        print("–†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        # --- –®–ê–ì 1: –†–∞—Å—á–µ—Ç—ã pandas-ta ---
        # (–í–µ—Å—å —ç—Ç–æ—Ç –±–ª–æ–∫ –°–ö–û–ü–ò–†–û–í–ê–ù –∏–∑ —Ç–≤–æ–µ–≥–æ —Å—Ç–∞—Ä–æ–≥–æ FeatureEngine. –û–Ω –∏–¥–µ–Ω—Ç–∏—á–µ–Ω.)
        ohlcv_df = self.df[['open', 'high', 'low', 'close', 'volume']].copy()
        ohlcv_df.ta.adx(length=14, append=True)
        ohlcv_df.ta.atr(length=14, append=True)
        ohlcv_df.ta.ema(length=200, append=True)
        ohlcv_df.ta.rsi(length=14, append=True)
        ohlcv_df.ta.vwap(anchor="D", append=True)
        ohlcv_df.ta.vwap(anchor="H", append=True)

        cols_to_copy = ['ADX_14', 'DMP_14', 'DMN_14', 'ATRr_14', 'EMA_200', 'RSI_14', 'VWAP_D', 'VWAP_H']
        for col in cols_to_copy:
            if col in ohlcv_df.columns:  # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É, –µ—Å–ª–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –Ω–µ —Ä–∞—Å—Å—á–∏—Ç–∞–ª—Å—è
                self.df[col] = ohlcv_df[col]

        self.df.rename(columns={
            'ADX_14': 'adx', 'DMP_14': 'dmp', 'DMN_14': 'dmn',
            'ATRr_14': 'atr', 'EMA_200': 'ema_200_1h', 'RSI_14': 'rsi_14_1h'
        }, inplace=True)

        # --- –®–ê–ì 2: –°–µ—Å—Å–∏–∏, –ö–∏–ª–ª–∑–æ–Ω—ã, –û—Ç—Ç–æ—Ä–∂–µ–Ω–∏—è ---
        # (–≠—Ç–æ—Ç –±–ª–æ–∫ —Ç–∞–∫–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞)
        if not pd.api.types.is_datetime64_any_dtype(self.df.index):
            self.df.index = pd.to_datetime(self.df.index)

        hour = self.df.index.hour
        self.df['is_asian_session'] = ((hour >= 0) & (hour < 9)).astype(int)
        self.df['is_london_session'] = ((hour >= 8) & (hour < 17)).astype(int)
        self.df['is_newyork_session'] = ((hour >= 13) & (hour < 22)).astype(int)
        self.df['is_asian_killzone'] = ((hour >= 0) & (hour < 4)).astype(int)
        self.df['is_london_killzone'] = ((hour >= 7) & (hour < 10)).astype(int)
        self.df['is_newyork_killzone'] = ((hour >= 12) & (hour < 15)).astype(int)

        self.df['bullish_rejection_power'] = (self.df['close'] - self.df['low']) / self.df['atr']
        self.df['bearish_rejection_power'] = (self.df['high'] - self.df['close']) / self.df['atr']
        volume_ma = self.df['volume'].rolling(20).mean()
        self.df['volume_spike_ratio'] = self.df['volume'] / volume_ma

        # --- –®–ê–ì 3: –ó–∞–≤–∏—Å–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–¥–∏—Å—Ç–∞–Ω—Ü–∏–∏, –≤—Ä–µ–º—è –∏ —Ç.–¥.) ---
        # (–≠—Ç–æ—Ç –±–ª–æ–∫ —Ç–∞–∫–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –∫–æ–¥–∞)
        self.df['range'] = self.df['high'] - self.df['low']
        self.df['is_compression'] = self.df['range'] <= self.df['range'].rolling(7).min()

        self.df['hour_sin'] = np.sin(2 * np.pi * self.df.index.hour / 24)
        self.df['hour_cos'] = np.cos(2 * np.pi * self.df.index.hour / 24)
        self.df['day_sin'] = np.sin(2 * np.pi * self.df.index.dayofweek / 7)
        self.df['day_cos'] = np.cos(2 * np.pi * self.df.index.dayofweek / 7)

        daily_df = self.df.resample('D').agg({'high': 'max', 'low': 'min'})
        self.df['static_pdh'] = daily_df['high'].shift(1).reindex(self.df.index, method='ffill')
        self.df['static_pdl'] = daily_df['low'].shift(1).reindex(self.df.index, method='ffill')

        # –î–∏—Å—Ç–∞–Ω—Ü–∏–∏ (—É–±–µ–¥–∏—Å—å, —á—Ç–æ —ç—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å –≤ self.df –∏–∑ prepare_master_dataframe)
        if 'poc_h' in self.df.columns:
            self.df['dist_to_poc_atr'] = (self.df['close'] - self.df['poc_h']) / self.df['atr']
        if 'poc_4h' in self.df.columns:
            self.df['dist_to_poc_4h_atr'] = (self.df['close'] - self.df['poc_4h']) / self.df['atr']
        if 'poc_d' in self.df.columns:
            self.df['dist_to_poc_d_atr'] = (self.df['close'] - self.df['poc_d']) / self.df['atr']

        self.df['dist_to_static_pdh_atr'] = (self.df['static_pdh'] - self.df['close']) / self.df['atr']
        self.df['dist_to_static_pdl_atr'] = (self.df['close'] - self.df['static_pdl']) / self.df['atr']

        if 'VWAP_D' in self.df.columns:
            self.df['dist_to_vwap_atr'] = (self.df['close'] - self.df['VWAP_D']) / self.df['atr']
        if 'VWAP_H' in self.df.columns:
            self.df['dist_to_vwap_h_atr'] = (self.df['close'] - self.df['VWAP_H']) / self.df['atr']

        # F&G
        if 'fear_greed_value' in self.df.columns:
            self.df['fear_greed_change_3d'] = self.df['fear_greed_value'].diff(periods=24 * 3)
            self.df['fear_greed_ma_3d'] = self.df['fear_greed_value'].rolling(window=24 * 3).mean()

        # FVG
        self.df['dist_to_static_bull_fvg_atr'] = np.where(self.df['low'] > self.df['high'].shift(2),
                                                          (self.df['close'] - self.df['high'].shift(2)) / self.df[
                                                              'atr'], np.nan)
        self.df['dist_to_static_bear_fvg_atr'] = np.where(self.df['high'] < self.df['low'].shift(2),
                                                          (self.df['low'].shift(2) - self.df['close']) / self.df['atr'],
                                                          np.nan)
        self.df['dist_to_static_bull_fvg_atr'].ffill(inplace=True)
        self.df['dist_to_static_bear_fvg_atr'].ffill(inplace=True)

        # –§–∏–ª—å—Ç—Ä –¢—Ä–µ–Ω–¥–∞ (HTF)
        if 'ema_50_4h' in self.df.columns and 'atr_14_4h' in self.df.columns:
            self.df['trend_strength_4h'] = (self.df['close'] - self.df['ema_50_4h']) / self.df['atr_14_4h']
        else:
            self.df['trend_strength_4h'] = 0

        print("–°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã.")

    # --- –†–ê–ó–î–ï–õ–ï–ù–ù–´–ï –§–£–ù–ö–¶–ò–ò –†–ê–ó–ú–ï–¢–ö–ò –¶–ï–õ–ò ---

    def _label_target_long(self):
        """
        [–õ–û–ì–ò–ö–ê –ò–ó –°–¢–ê–†–û–ì–û FeatureEngine_LONG]
        –ò—â–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω "Rejection" –Ω–∞ –∫–ª—é—á–µ–≤–æ–º —É—Ä–æ–≤–Ω–µ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ –¥–ª—è –õ–û–ù–ì–ê.
        """
        print("–†–∞–∑–º–µ—Ç–∫–∞ LONG-—Ç–∞—Ä–≥–µ—Ç–æ–≤...")
        df = self.df.copy()

        pdl = df['static_pdl'].shift(1)
        is_asian = df['is_asian_session'] == 1
        daily_asian_low = df['low'].where(is_asian).groupby(df.index.date).transform('min')
        asian_session_low = daily_asian_low.ffill()
        is_london = df['is_london_session'] == 1
        daily_london_low = df['low'].where(is_london).groupby(df.index.date).transform('min')
        london_session_low = daily_london_low.ffill()

        rejection_pdl = (df['low'] < pdl) & (df['close'] > pdl)
        rejection_asian = (df['low'] < asian_session_low) & (df['close'] > asian_session_low) & ~is_asian
        rejection_london = (df['low'] < london_session_low) & (df['close'] > london_session_low) & ~is_london

        df['target'] = (rejection_pdl | rejection_asian | rejection_london).astype(int)


        self.df['target'] = df['target'].shift(-1).fillna(0)


    def _label_target_short(self, look_forward_bars=6):
        """
        [–ù–û–í–ê–Ø –ó–ê–î–ê–ß–ê v11 - Flexible Sessions Regression]
        –ó–∞–¥–∞—á–∞: –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –†–ê–ó–ú–ï–† –¥–≤–∏–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ –ì–ò–ë–ö–û–ì–û —Å–µ—Å—Å–∏–æ–Ω–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞.
        - –í –õ–æ–Ω–¥–æ–Ω–µ –∏—â–µ–º —Å–≤–∏–ø –ê–∑–∏–∏.
        - –í –ù—å—é-–ô–æ—Ä–∫–µ –∏—â–µ–º —Å–≤–∏–ø –º–∞–∫—Å–∏–º—É–º–∞ –¥–Ω—è (–ê–∑–∏—è –∏–ª–∏ –õ–æ–Ω–¥–æ–Ω).
        """
        print("–†–∞–∑–º–µ—Ç–∫–∞ –†–ï–ì–†–ï–°–°–ò–û–ù–ù–û–ô –¶–µ–ª–∏ (v11 - –ì–∏–±–∫–∏–µ –°–µ—Å—Å–∏–∏)...")
        df = self.df

        # --- 1. –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º—É–º—ã –∏ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –ö–ê–ñ–î–û–ô —Å–µ—Å—Å–∏–∏ ---
        is_asian = (df['is_asian_session'] == 1)
        asia_high = df['high'].where(is_asian).groupby(df.index.date).transform('max').ffill()
        asia_low = df['low'].where(is_asian).groupby(df.index.date).transform('min').ffill()
        asia_range = (asia_high - asia_low)

        is_london = (df['is_london_session'] == 1)
        london_high = df['high'].where(is_london).groupby(df.index.date).transform('max').ffill()
        london_low = df['low'].where(is_london).groupby(df.index.date).transform('min').ffill()
        london_range = (london_high - london_low)

        # --- 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ö–ê–ö–û–ô —É—Ä–æ–≤–µ–Ω—å –∏ –¥–∏–∞–ø–∞–∑–æ–Ω —è–≤–ª—è—é—Ç—Å—è —Ü–µ–ª—è–º–∏ –¥–ª—è –ö–ê–ñ–î–û–ô —Å–≤–µ—á–∏ ---
        target_liquidity_level = pd.Series(float('nan'), index=df.index)
        normalization_range = pd.Series(float('nan'), index=df.index)

        # –î–ª—è —Å–≤–µ—á–µ–π –≤ –õ–æ–Ω–¥–æ–Ω—Å–∫–æ–π –ö–ó, —Ü–µ–ª—å - —ç—Ç–æ –º–∞–∫—Å–∏–º—É–º –ê–∑–∏–∏
        is_london_kz = (df['is_london_killzone'] == 1)
        target_liquidity_level.loc[is_london_kz] = asia_high.shift(1)
        normalization_range.loc[is_london_kz] = asia_range.shift(1)

        # –î–ª—è —Å–≤–µ—á–µ–π –≤ –ù—å—é-–ô–æ—Ä–∫—Å–∫–æ–π –ö–ó, —Ü–µ–ª—å - —ç—Ç–æ –ú–ê–ö–°–ò–ú–£–ú –∏–∑ —Ö–∞—è –ê–∑–∏–∏ –∏ —Ö–∞—è –õ–æ–Ω–¥–æ–Ω–∞
        is_newyork_kz = (df['is_newyork_killzone'] == 1)
        # .shift(1) –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã –¥–∞–Ω–Ω—ã–µ –Ω–∞ –º–æ–º–µ–Ω—Ç NY KZ –±—ã–ª–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏
        daily_high_before_ny = pd.concat([asia_high, london_high]).groupby(level=0).max().shift(1)
        target_liquidity_level.loc[is_newyork_kz] = daily_high_before_ny

        # –î–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–∏–π –∏–∑ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
        norm_range_before_ny = pd.concat([asia_range, london_range]).groupby(level=0).max().shift(1)
        normalization_range.loc[is_newyork_kz] = norm_range_before_ny

        # --- 3. –ù–∞—Ö–æ–¥–∏–º —Å–≤–µ—á–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –Ω–∞—à–µ–º—É –ì–ò–ë–ö–û–ú–£ –ø–∞—Ç—Ç–µ—Ä–Ω—É ---
        price_pattern_signal = (
                (df['high'] > target_liquidity_level) &
                (df['close'] < target_liquidity_level)
        )

        candidate_candles = df[price_pattern_signal]

        final_target = pd.Series(float('nan'), index=df.index)

        # --- 4. –†–ê–°–°–ß–ò–¢–´–í–ê–ï–ú –†–ï–ó–£–õ–¨–¢–ê–¢ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ ---
        for timestamp, candle in candidate_candles.iterrows():
            entry_price = candle['close']
            current_norm_range = normalization_range.loc[timestamp]

            if pd.isna(current_norm_range) or current_norm_range == 0:
                continue

            future_window = df.loc[timestamp:].iloc[1: 1 + look_forward_bars]

            if not future_window.empty:
                max_drawdown_price = future_window['low'].min()
                price_move = entry_price - max_drawdown_price
                normalized_move = max(0, price_move / current_norm_range)
                final_target.loc[timestamp] = normalized_move

        self.df['target'] = final_target
        print(f"–†–∞–∑–º–µ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ù–∞–π–¥–µ–Ω–æ {len(candidate_candles)} –≥–∏–±–∫–∏—Ö —Å–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")

    def run(self, model_type: str, create_target: bool = False):
        """
        [–§–ò–ù–ê–õ–¨–ù–ê–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø]
        –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –ø–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
        1. –†–∞—Å—á–µ—Ç (–ü—Ä–µ-–∫–∞–ª—å–∫, –°—Ç–∞—Ç–∏–∫–∞)
        2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤
        3. –ì–ª–∞–≤–Ω—ã–π –¶–∏–∫–ª (–∫–æ—Ç–æ—Ä—ã–π –°–û–ó–î–ê–ï–¢ VSA-—Ñ–∏—á–∏ –∏ –í–µ–∫—Ç–æ—Ä –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏)
        4. –†–∞–∑–º–µ—Ç–∫–∞ (–∫–æ—Ç–æ—Ä–∞—è –ß–ò–¢–ê–ï–¢ VSA-—Ñ–∏—á–∏)
        5. –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è.
        """

        # --- –≠–¢–ê–ü 1: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞—Å—á–µ—Ç—ã ---
        print("–ó–∞–ø—É—Å–∫ Feature Engine...")
        self._precalculate_swing_points(fractal_order=5)
        self._find_significant_liquidity(rest_period_bars=24) # 2. <-- –î–û–ë–ê–í–¨ –≠–¢–û–¢ –í–´–ó–û–í (–§–∏–ª—å—Ç—Ä—É–µ—Ç –∏—Ö)
        self._calculate_market_structure()
        self._calculate_static_features()

        # --- –≠–¢–ê–ü 2: –í—ã–±–æ—Ä —Å–ø–∏—Å–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–Ω–æ –ü–û–ö–ê –ù–ï –í–´–ó–´–í–ê–ï–ú —Ä–∞–∑–º–µ—Ç–∫—É) ---
        static_feature_names = []
        if model_type == 'LONG':
            static_feature_names = self.STATIC_FEATURES_LONG
        elif model_type == 'SHORT':
            static_feature_names = self.STATIC_FEATURES_SHORT
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π model_type: {model_type}. –û–∂–∏–¥–∞–µ—Ç—Å—è 'LONG' –∏–ª–∏ 'SHORT'.")

        # --- –≠–¢–ê–ü 3: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ ---
        print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ (–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å + VSA)...")

        # 3.1 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –í–µ–∫—Ç–æ—Ä–∞ –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏
        N_CLOSEST_LEVELS = 3
        self.liquidity_vector_features = []
        for i in range(1, N_CLOSEST_LEVELS + 1):
            self.liquidity_vector_features.append(f'dist_to_level_{i}_atr')
            self.liquidity_vector_features.append(f'type_of_level_{i}')
        for col in self.liquidity_vector_features:
            self.df[col] = 0.0

        # 3.2 –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è VSA-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        vsa_cols = ['dynamic_leg_vol', 'dynamic_candle_1m_vol', 'dynamic_vol_ratio']
        for col in vsa_cols:
            self.df[col] = 0.0

        # --- –≠–¢–ê–ü 4: –ï–î–ò–ù–´–ô –ò–¢–ï–†–ê–¢–ò–í–ù–´–ô –¶–ò–ö–õ (–°–û–ó–î–ê–ï–¢ –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏) ---
        print("–ó–∞–ø—É—Å–∫ –≥–ª–∞–≤–Ω–æ–≥–æ –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ (VSA + Liquidity Vector)...")

        prev_day = None
        WARMUP_BARS = 10

        for i in range(WARMUP_BARS, len(self.df)):

            # --- 4.1: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏ ---
            current_timestamp = self.df.index[i]
            current_high = self.df['high'].iloc[i]
            current_low = self.df['low'].iloc[i]
            current_close = self.df['close'].iloc[i]
            # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ atr –Ω–µ NaN (–≤–∞–∂–Ω–æ –¥–ª—è –¥–µ–ª–µ–Ω–∏—è)
            current_atr = self.df['atr'].iloc[i]
            if pd.isna(current_atr) or current_atr == 0:
                current_atr = 1.0  # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å

            # --- 4.2: –†–ê–°–ß–ï–¢ –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–• VSA-–ü–†–ò–ó–ù–ê–ö–û–í ---
            try:
                if model_type == 'SHORT':
                    previous_swings = self.all_swing_low_timestamps[self.all_swing_low_timestamps < current_timestamp]
                    if previous_swings.empty: raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ—à–ª—ã—Ö –º–∏–Ω–∏–º—É–º–∞—Ö")
                    leg_start_time = previous_swings.max()

                elif model_type == 'LONG':  # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥–∏–∫—É –¥–ª—è –õ–æ–Ω–≥–∞
                    previous_swings = self.all_swing_high_timestamps[self.all_swing_high_timestamps < current_timestamp]
                    if previous_swings.empty: raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ—à–ª—ã—Ö –º–∞–∫—Å–∏–º—É–º–∞—Ö")
                    leg_start_time = previous_swings.max()

                leg_end_time = current_timestamp - pd.Timedelta(seconds=1)
                df_1m_leg_slice = self.df_1m.loc[leg_start_time:leg_end_time]
                leg_volume = df_1m_leg_slice['volume'].sum()

                candle_end_time = current_timestamp + pd.Timedelta(minutes=59, seconds=59)
                df_1m_candle_slice = self.df_1m.loc[current_timestamp:candle_end_time]
                candle_1m_volume = df_1m_candle_slice['volume'].sum()

                if leg_volume > 0:
                    dynamic_ratio = candle_1m_volume / leg_volume
                else:
                    dynamic_ratio = 0

                self.df.loc[current_timestamp, 'dynamic_leg_vol'] = leg_volume
                self.df.loc[current_timestamp, 'dynamic_candle_1m_vol'] = candle_1m_volume
                self.df.loc[current_timestamp, 'dynamic_vol_ratio'] = dynamic_ratio

            except Exception as e:
                self.df.loc[current_timestamp, 'dynamic_leg_vol'] = 0
                self.df.loc[current_timestamp, 'dynamic_candle_1m_vol'] = 0
                self.df.loc[current_timestamp, 'dynamic_vol_ratio'] = 0

            # --- 4.3: –†–ê–°–ß–ï–¢ –í–ï–ö–¢–û–†–ê –õ–ò–ö–í–ò–î–ù–û–°–¢–ò ---

            self._update_liquidity_status(current_high, current_low)

            if prev_day != current_timestamp.date():
                if prev_day is not None:
                    pdh = self.df.loc[self.df.index.date == prev_day, 'high'].max()
                    pdl = self.df.loc[self.df.index.date == prev_day, 'low'].min()
                    if not np.isnan(pdh): self._add_liquidity_zone('PDH', pdh)
                    if not np.isnan(pdl): self._add_liquidity_zone('PDL', pdl)
                prev_day = current_timestamp.date()

            if (i > 1) and (self.df['high'].iloc[i - 1] < self.df['low'].iloc[i - 2]):
                self._add_liquidity_zone('BullishFVG', self.df['high'].iloc[i - 1], self.df['low'].iloc[i - 2])
            if (i > 1) and (self.df['low'].iloc[i - 1] > self.df['high'].iloc[i - 2]):
                self._add_liquidity_zone('BearishFVG', self.df['high'].iloc[i - 2], self.df['low'].iloc[i - 1])

            active_zones = [z for z in self.liquidity_map if z['status'] == 'active']

            zone_type_map = {'PDH': 1, 'PDL': 2, 'BullishFVG': 3, 'BearishFVG': 4, 'POC_H': 5, 'POC_4H': 6, 'POC_D': 7}
            levels_with_dist = []
            for zone in active_zones:
                level_price = (zone['price_start'] + zone['price_end']) / 2
                distance = current_close - level_price
                zone_type_code = zone_type_map.get(zone['type'], 0)
                if zone_type_code > 0:
                    levels_with_dist.append((distance, zone_type_code))

            if 'poc_h' in self.df.columns and pd.notna(self.df['poc_h'].iloc[i]):
                levels_with_dist.append((current_close - self.df['poc_h'].iloc[i], zone_type_map['POC_H']))
            if 'poc_4h' in self.df.columns and pd.notna(self.df['poc_4h'].iloc[i]):
                levels_with_dist.append((current_close - self.df['poc_4h'].iloc[i], zone_type_map['POC_4H']))
            if 'poc_d' in self.df.columns and pd.notna(self.df['poc_d'].iloc[i]):
                levels_with_dist.append((current_close - self.df['poc_d'].iloc[i], zone_type_map['POC_D']))

            levels_with_dist.sort(key=lambda x: abs(x[0]))

            for j in range(N_CLOSEST_LEVELS):
                feature_dist_name = f'dist_to_level_{j + 1}_atr'
                feature_type_name = f'type_of_level_{j + 1}'

                if j < len(levels_with_dist):
                    signed_dist = levels_with_dist[j][0]
                    level_type = levels_with_dist[j][1]
                    dist_atr = signed_dist / current_atr  # –ú—ã —É–∂–µ –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ ATR –Ω–∞ –Ω–æ–ª—å –≤ –Ω–∞—á–∞–ª–µ —Ü–∏–∫–ª–∞
                    self.df.loc[current_timestamp, feature_dist_name] = dist_atr
                    self.df.loc[current_timestamp, feature_type_name] = level_type
                else:
                    self.df.loc[current_timestamp, feature_dist_name] = 999
                    self.df.loc[current_timestamp, feature_type_name] = 0

        # --- –ö–û–ù–ï–¶ –ì–õ–ê–í–ù–û–ì–û –¶–ò–ö–õ–ê ---

        # --- –≠–¢–ê–ü 5: –†–ê–ó–ú–ï–¢–ö–ê (–¢–ï–ü–ï–†–¨ –û–ù–ê –í–´–ü–û–õ–ù–Ø–ï–¢–°–Ø –ü–û–°–õ–ï –¶–ò–ö–õ–ê) ---
        # –¢–µ–ø–µ—Ä—å self.df –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–ø–æ–ª–Ω–µ–Ω –í–°–ï–ú–ò –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (–≤–∫–ª—é—á–∞—è dynamic_vol_ratio)
        if create_target:
            print("–ó–∞–ø—É—Å–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–∏ (Labeling)...")
            if model_type == 'LONG':
                self._label_target_long()
            elif model_type == 'SHORT':
                self._label_target_short()  # <-- –¢–µ–ø–µ—Ä—å —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Å—Ä–∞–±–æ—Ç–∞–µ—Ç, —Ç.–∫. –∫–æ–ª–æ–Ω–∫–∞ 'dynamic_vol_ratio' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

        # --- –≠–¢–ê–ü 6: –§–∏–Ω–∞–ª—å–Ω–æ–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ X –∏ y ---
        print("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")

        all_feature_names = static_feature_names + self.liquidity_vector_features
        all_feature_names = [col for col in all_feature_names if col in self.df.columns]

        if create_target:
            columns_to_select = all_feature_names + ['target']
            columns_to_select = [col for col in columns_to_select if col in self.df.columns]
            final_df = self.df[columns_to_select].copy()
            y = final_df.get('target')
        else:
            columns_to_select = all_feature_names
            final_df = self.df[columns_to_select].copy()
            y = None

        final_df.replace([np.inf, -np.inf], 999, inplace=True)
        final_df.fillna(0, inplace=True)

        X = final_df.loc[:, all_feature_names]

        print("–ò–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω.")
        return X, y, self.df.loc[X.index]

# ==============================================================================
# –†–ê–ó–î–ï–õ 2.1: –ù–û–í–´–ô FEATURE ENGINE –î–õ–Ø –ú–û–î–ï–õ–ò-"–¢–ê–ö–¢–ò–ö–ê" (5–º –¢–§)
# ==============================================================================

class FeatureEngine_Tactician:
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–∏–∫—Ä–æ—Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è 5-–º–∏–Ω—É—Ç–Ω–æ–≥–æ –¢–§ (V2)."""

    def __init__(self, data):
        self.df = data.copy()

    def run(self):
        print("–°–æ–∑–¥–∞–Ω–∏–µ 5–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è '–¢–∞–∫—Ç–∏–∫–∞' (V2)...")

        # --- –ë–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã ---
        rsi_series = self.df.ta.rsi(length=5, append=False)
        if rsi_series is not None:
            self.df['rsi_5_5m'] = rsi_series

        ema_10_series = self.df.ta.ema(length=10, append=False)
        if ema_10_series is not None:
            self.df['dist_to_ema10_5m'] = (self.df['close'] - ema_10_series) / self.df['close']

        vol_ma_20 = self.df['volume'].rolling(20).mean()
        self.df['volume_spike'] = self.df['volume'] / vol_ma_20

        self.df['candle_in_hour'] = self.df.index.minute / 5

        # --- ‚úÖ –ù–ê–ß–ê–õ–û –ù–û–í–û–ì–û –ë–õ–û–ö–ê: –ê–ù–ê–õ–ò–ó –°–í–ï–ß–ï–ô ---

        # 1. –†–∞—Å—á–µ—Ç ATR –Ω–∞ 5–º –¢–§
        atr_5m = self.df.ta.atr(length=14, append=False)

        # 2. –†–∞–∑–º–µ—Ä —Ç–µ–ª–∞ —Å–≤–µ—á–∏, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ ATR
        body_size = abs(self.df['close'] - self.df['open'])
        self.df['body_size_vs_atr'] = body_size / atr_5m

        # 3. –†–∞–∑–º–µ—Ä –Ω–∏–∂–Ω–µ–≥–æ —Ñ–∏—Ç–∏–ª—è
        lower_wick = (self.df[['open', 'close']].min(axis=1) - self.df['low'])
        self.df['lower_wick_vs_atr'] = lower_wick / atr_5m

        # 4. –†–∞–∑–º–µ—Ä –≤–µ—Ä—Ö–Ω–µ–≥–æ —Ñ–∏—Ç–∏–ª—è
        upper_wick = (self.df['high'] - self.df[['open', 'close']].max(axis=1))
        self.df['upper_wick_vs_atr'] = upper_wick / atr_5m

        # --- ‚úÖ –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –ë–õ–û–ö–ê ---

        # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        self.df.fillna(method='bfill', inplace=True)
        self.df.fillna(method='ffill', inplace=True)

        feature_names = [
            'rsi_5_5m', 'dist_to_ema10_5m', 'volume_spike', 'candle_in_hour',
            'body_size_vs_atr', 'lower_wick_vs_atr', 'upper_wick_vs_atr'  # –ù–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        ]

        existing_features = [col for col in feature_names if col in self.df.columns]
        X = self.df[existing_features]

        y = self.df['target'] if 'target' in self.df.columns else None

        return X, y


# ==============================================================================
# –†–ê–ó–î–ï–õ 4: –ë–≠–ö–¢–ï–°–¢–ò–ù–ì –ò –û–¶–ï–ù–ö–ê (–í–µ—Ä—Å–∏—è –¥–ª—è –±–∏–Ω–∞—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
# ==============================================================================
class Backtester:
    def __init__(self, price_data, initial_capital=initial_capital, fee=0.001, timeframe='1h',):
        self.price_data = price_data.copy()
        self.initial_capital = initial_capital
        self.fee = fee
        self.timeframe = timeframe
        self.trades = []

    def calculate_performance(self, equity_curve):
        periods_in_year = {
            '1m': 365 * 24 * 60,
            '5m': 365 * 24 * 12,
            '15m': 365 * 24 * 4,
            '1h': 365 * 24,
            '4h': 365 * 6,
            '1d': 365
        }
        annualization_factor = np.sqrt(periods_in_year.get(self.timeframe, 365 * 24))

        total_return = (equity_curve.iloc[-1] / self.initial_capital) - 1
        returns = equity_curve.pct_change().dropna()

        if len(returns) < 2 or returns.std() == 0:
            sharpe_ratio = 0.0
        else:
            sharpe_ratio = annualization_factor * returns.mean() / returns.std()

        cumulative = equity_curve / self.initial_capital
        peak = cumulative.cummax()
        drawdown = (cumulative - peak) / peak
        max_drawdown = drawdown.min()
        print(annualization_factor)  # —á—Ç–æ–±—ã —É–¥–æ—Å—Ç–æ–≤–µ—Ä–∏—Ç—å—Å—è —á—Ç–æ –≤—ã–±—Ä–∞–Ω –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
        return {"–ò—Ç–æ–≥–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å (%)": total_return * 100,  # <-- –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª—é—á
                "–ö–æ—ç—Ñ. –®–∞—Ä–ø–∞ (–≥–æ–¥–æ–≤–æ–π)": sharpe_ratio,
                "–ú–∞–∫—Å. –ø—Ä–æ—Å–∞–¥–∫–∞ (%)": max_drawdown * 100,
                "–ò—Ç–æ–≥–æ–≤—ã–π –∫–∞–ø–∏—Ç–∞–ª": equity_curve.iloc[-1]  # <-- –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
                }


    def run_buy_and_hold(self):
        equity = self.initial_capital * (self.price_data['close'] / self.price_data['close'].iloc[0])
        stats = self.calculate_performance(equity)
        stats.update({"–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫": 1})
        return stats

    def run_dma_crossover(self):
        # –≠—Ç–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–∏
        return {"–ò—Ç–æ–≥–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å (%)": 0.0, "–ö–æ—ç—Ñ. –®–∞—Ä–ø–∞ (–≥–æ–¥–æ–≤–æ–π)": 0.0, "–ú–∞–∫—Å. –ø—Ä–æ—Å–∞–¥–∫–∞ (%)": 0.0, "–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫": 0}

        # –ü–æ–º–µ—Å—Ç–∏—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥ –≤–Ω—É—Ç—Ä—å class Backtester –≤ trading_tools.py

    def equity_curve_from_trades(self, trades_df: pd.DataFrame, price_series: pd.Series) -> pd.Series:
        """
        –°—Ç—Ä–æ–∏—Ç –∫—Ä–∏–≤—É—é –∫–∞–ø–∏—Ç–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ DataFrame'–∞ —Å–æ —Å–¥–µ–ª–∫–∞–º–∏.
        """
        if trades_df.empty:
            return pd.Series([self.initial_capital], index=[price_series.index[0]])

        equity = pd.Series(index=price_series.index)
        equity.iloc[0] = self.initial_capital
        capital = self.initial_capital

        last_trade_exit_time = pd.Timestamp.min

        for _, trade in trades_df.iterrows():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–¥–µ–ª–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –¥–æ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–π
            if trade['entry_time'] < last_trade_exit_time:
                continue

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º PnL –¥–ª—è —Å–¥–µ–ª–∫–∏
            if trade['direction'] == 1:  # Long
                pnl_ratio = (trade['exit_price'] / trade['entry_price']) * (1 - self.fee) ** 2
            else:  # Short
                pnl_ratio = (trade['entry_price'] / trade['exit_price']) * (1 - self.fee) ** 2

            capital *= pnl_ratio

            # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –≤—Ä–µ–º–µ–Ω–∏ –≤—ã—Ö–æ–¥–∞ –∏–∑ —Å–¥–µ–ª–∫–∏
            exit_idx = price_series.index.get_indexer([trade['exit_time']], method='nearest')[0]
            equity.iloc[exit_idx] = capital
            last_trade_exit_time = trade['exit_time']

        equity.ffill(inplace=True)
        equity.bfill(inplace=True)  # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω–∞—á–∞–ª–æ, –µ—Å–ª–∏ –ø–µ—Ä–≤–∞—è —Å–¥–µ–ª–∫–∞ –Ω–µ –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ
        return equity

    def run_simulation_from_trades(self, trades_df: pd.DataFrame):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±—ç–∫—Ç–µ—Å—Ç–∞ –ø–æ —Å–ø–∏—Å–∫—É —Å–¥–µ–ª–æ–∫.
        """
        # --- –ù–ê–ß–ê–õ–û –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø ---
        # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, —á—Ç–æ –Ω–∞–º –ø–µ—Ä–µ–¥–∞–ª–∏: —Ü–µ–ª—ã–π DataFrame –∏–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü (Series)
        if isinstance(self.price_data, pd.DataFrame):
            price_series = self.price_data['close']
        else:
            price_series = self.price_data

        equity_curve = self.equity_curve_from_trades(trades_df, price_series)
        stats = self.calculate_performance(equity_curve)
        stats['–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫'] = len(trades_df)
        return stats

    def run_smc_strategy(self, signals_df, strategy_params):
        """
        –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±—ç–∫—Ç–µ—Å—Ç–µ—Ä –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ "Smart Money".
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π —Å—Ç–æ–ø –∏ –±—ã—Å—Ç—Ä—ã–π –≤—ã—Ö–æ–¥.
        """
        if self.price_data.empty:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö
            return self.calculate_performance(pd.Series([self.initial_capital], index=self.price_data.index))

        df = self.price_data.copy().join(signals_df)
        df['prediction'].fillna(0, inplace=True)
        self.trades = []

        equity = self.initial_capital
        equity_history = [self.initial_capital] * len(df)  # –°–æ–∑–¥–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å—Ä–∞–∑—É
        position = 0

        # --- –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –≤—ã—Ö–æ–¥–∞ ---
        EXIT_AFTER_BARS = 5  # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Å–¥–µ–ª–∫–∏ —á–µ—Ä–µ–∑ 5 —Å–≤–µ—á–µ–π, –µ—Å–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª SL/TP
        entry_bar_index = -1

        for i in range(1, len(df)):
            current_open = df['open'].iloc[i]

            # --- –õ–æ–≥–∏–∫–∞ –≤—ã—Ö–æ–¥–∞ ---
            if position != 0:
                # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—Ö–æ–¥ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                if i >= entry_bar_index + EXIT_AFTER_BARS:
                    exit_price = current_open  # –í—ã—Ö–æ–¥–∏–º –ø–æ –æ—Ç–∫—Ä—ã—Ç–∏—é —Å–ª–µ–¥—É—é—â–µ–π —Å–≤–µ—á–∏
                    pnl_ratio = (exit_price / entry_price) if position == 1 else (entry_price / exit_price)
                    equity *= pnl_ratio * (1 - self.fee) ** 2
                    position = 0

                # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—Ö–æ–¥ –ø–æ SL/TP (–æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
                elif position == 1 and (df['low'].iloc[i] <= stop_loss or df['high'].iloc[i] >= take_profit):
                    exit_price = stop_loss if df['low'].iloc[i] <= stop_loss else take_profit
                    equity *= (exit_price / entry_price) * (1 - self.fee) ** 2
                    position = 0
                elif position == -1 and (df['high'].iloc[i] >= stop_loss or df['low'].iloc[i] <= take_profit):
                    exit_price = stop_loss if df['high'].iloc[i] >= stop_loss else take_profit
                    equity *= (entry_price / exit_price) * (1 - self.fee) ** 2
                    position = 0

            # --- –õ–æ–≥–∏–∫–∞ –≤—Ö–æ–¥–∞ ---
            if position == 0:
                signal = int(df['prediction'].iloc[i - 1])  # –ë–µ—Ä–µ–º —Å–∏–≥–Ω–∞–ª —Å –ü–†–ï–î–´–î–£–©–ï–ô —Å–≤–µ—á–∏
                if signal != 0:
                    entry_price = current_open  # –í—Ö–æ–¥–∏–º –ø–æ –æ—Ç–∫—Ä—ã—Ç–∏—é —Ç–µ–∫—É—â–µ–π —Å–≤–µ—á–∏
                    entry_bar_index = i
                    position = signal
                    self.trades.append(i)

                    # --- –ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∏ SL/TP ---
                    # –°—Ç–æ–ø —Å—Ç–∞–≤–∏–º –∑–∞ –º–∏–Ω–∏–º—É–º/–º–∞–∫—Å–∏–º—É–º —Å–∏–≥–Ω–∞–ª—å–Ω–æ–π —Å–≤–µ—á–∏
                    risk_per_share = abs(entry_price - df['low'].iloc[i - 1]) if signal == 1 else abs(
                        df['high'].iloc[i - 1] - entry_price)

                    # –¢–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç —Å—Ç–∞–≤–∏–º —Å –Ω–µ–±–æ–ª—å—à–∏–º, –Ω–æ –Ω–∞–¥–µ–∂–Ω—ã–º RR
                    take_profit_amount = risk_per_share * strategy_params.get('rr_ratio', 1.5)

                    if signal == 1:
                        stop_loss = df['low'].iloc[i - 1]
                        take_profit = entry_price + take_profit_amount
                    else:  # signal == -1
                        stop_loss = df['high'].iloc[i - 1]
                        take_profit = entry_price - take_profit_amount

            equity_history[i] = equity

        equity_series = pd.Series(equity_history, index=df.index)
        stats = self.calculate_performance(equity_series)
        stats.update({"–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫": len(self.trades)})
        self.trades = []
        return stats


    def run_ml_strategy(self, signals_df, strategy_params):
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞ –Ω–µ –ø—É—Å—Ç—ã–µ
        if self.price_data.empty:
            return self.calculate_performance(pd.Series([self.initial_capital]))

        df = self.price_data.copy().join(signals_df)

        # –ó–∞–ø–æ–ª–Ω—è–µ–º NaN –≤ —Å–∏–≥–Ω–∞–ª–∞—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        df['prediction'].fillna(0, inplace=True)
        df['strength'].fillna('none', inplace=True)

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ ATR —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
        if 'atr' not in df.columns:
            raise ValueError("ATR –∫–æ–ª–æ–Ω–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞.")
        df['atr'].fillna(method='ffill', inplace=True)

        atr_multiplier_stop = strategy_params['atr_multiplier_stop']
        rr_ratio_low = strategy_params['rr_ratio_low']
        rr_ratio_high = strategy_params['rr_ratio_high']

        equity = self.initial_capital
        position = 0  # 0: –Ω–µ—Ç –ø–æ–∑–∏—Ü–∏–∏, 1: –ª–æ–Ω–≥, -1: —à–æ—Ä—Ç
        entry_price = 0
        stop_loss = 0
        take_profit = 0

        # –°–ø–∏—Å–æ–∫ –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞–ø–∏—Ç–∞–ª–∞
        equity_history = [self.initial_capital]

        for i in range(1, len(df)):
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—ã—Ö–æ–¥ –∏–∑ –ø–æ–∑–∏—Ü–∏–∏
            if position == 1:  # –ï—Å–ª–∏ –º—ã –≤ –ª–æ–Ω–≥–µ
                if df['low'].iloc[i] <= stop_loss:
                    # –í—ã—Ö–æ–¥ –ø–æ —Å—Ç–æ–ø-–ª–æ—Å—Å—É
                    equity *= (stop_loss / entry_price) * (1 - self.fee) ** 2
                    position = 0
                elif df['high'].iloc[i] >= take_profit:
                    # –í—ã—Ö–æ–¥ –ø–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç—É
                    equity *= (take_profit / entry_price) * (1 - self.fee) ** 2
                    position = 0

            elif position == -1:  # –ï—Å–ª–∏ –º—ã –≤ —à–æ—Ä—Ç–µ
                if df['high'].iloc[i] >= stop_loss:
                    # –í—ã—Ö–æ–¥ –ø–æ —Å—Ç–æ–ø-–ª–æ—Å—Å—É
                    equity *= (entry_price / stop_loss) * (1 - self.fee) ** 2
                    position = 0
                elif df['low'].iloc[i] <= take_profit:
                    # –í—ã—Ö–æ–¥ –ø–æ —Ç–µ–π–∫-–ø—Ä–æ—Ñ–∏—Ç—É
                    equity *= (entry_price / take_profit) * (1 - self.fee) ** 2
                    position = 0

            # –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥ –≤ –Ω–æ–≤—É—é –ø–æ–∑–∏—Ü–∏—é
            if position == 0:
                signal = int(df['prediction'].iloc[i])
                strength = df['strength'].iloc[i]

                if signal != 0 and strength != 'none':
                    atr_value = df['atr'].iloc[i]
                    if pd.notna(atr_value) and atr_value > 0:
                        entry_price = df['close'].iloc[i]
                        risk_reward_ratio = rr_ratio_high if strength == 'high' else rr_ratio_low

                        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º SL/TP –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞
                        sl_amount = atr_value * atr_multiplier_stop
                        tp_amount = sl_amount * risk_reward_ratio

                        if signal == 1:  # –õ–æ–Ω–≥
                            stop_loss = entry_price - sl_amount
                            take_profit = entry_price + tp_amount
                        else:  # –®–æ—Ä—Ç (–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ -1)
                            stop_loss = entry_price + sl_amount
                            take_profit = entry_price - tp_amount

                        position = signal
                        self.trades.append(i)  # –ü—Ä–æ—Å—Ç–æ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–∫—Ç —Å–¥–µ–ª–∫–∏

            equity_history.append(equity)

        # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Ç–æ–≥–æ–≤ ---
        # –°–æ–∑–¥–∞–µ–º Series –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∫–∞–ø–∏—Ç–∞–ª–∞
        equity_series = pd.Series(equity_history, index=df.index[:len(equity_history)])

        stats = self.calculate_performance(equity_series)
        stats.update({"–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫": len(self.trades)})

        # –í–∞–∂–Ω–æ! –û—á–∏—â–∞–µ–º —Å–¥–µ–ª–∫–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—É—Å–∫–∞ –Ω–∞ —ç—Ç–æ–º –∂–µ –æ–±—ä–µ–∫—Ç–µ
        self.trades = []

        return stats

        # (–î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –≤ –∫–ª–∞—Å—Å Backtester)

    def run_adaptive_smc_strategy(self, signals_df, strategy_params):
        """
        –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø –° –ê–î–ê–ü–¢–ò–í–ù–´–ú –¢–ï–ô–ö-–ü–†–û–§–ò–¢–û–ú.
        –†–∞–∑–º–µ—Ä Take-Profit –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –æ–±—ä–µ–º–∞ –Ω–∞ —Å–∏–≥–Ω–∞–ª—å–Ω–æ–π —Å–≤–µ—á–µ.
        """
        if self.price_data.empty:
            return self.calculate_performance(pd.Series([self.initial_capital], index=self.price_data.index))

        df = self.price_data.copy().join(signals_df)
        if 'volume_spike_ratio' not in df.columns:
            raise ValueError("–ü—Ä–∏–∑–Ω–∞–∫ 'volume_spike_ratio' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞!")

        df['prediction'].fillna(0, inplace=True)
        self.trades = []
        equity = self.initial_capital
        equity_history = [self.initial_capital] * len(df)
        position = 0
        entry_price = 0
        stop_loss = 0
        take_profit = 0

        EXIT_AFTER_BARS = strategy_params.get('exit_after_bars', 8)
        entry_bar_index = -1

        for i in range(1, len(df)):
            current_open = df['open'].iloc[i]

            # --- –õ–æ–≥–∏–∫–∞ –≤—ã—Ö–æ–¥–∞ ---
            if position != 0:
                exit_reason = None
                if i >= entry_bar_index + EXIT_AFTER_BARS:
                    exit_reason = "time_exit"
                elif position == 1 and df['low'].iloc[i] <= stop_loss:
                    exit_reason = "stop_loss"
                elif position == 1 and df['high'].iloc[i] >= take_profit:
                    exit_reason = "take_profit"
                elif position == -1 and df['high'].iloc[i] >= stop_loss:
                    exit_reason = "stop_loss"
                elif position == -1 and df['low'].iloc[i] <= take_profit:
                    exit_reason = "take_profit"

                if exit_reason:
                    exit_price = current_open
                    if exit_reason == "stop_loss": exit_price = stop_loss
                    if exit_reason == "take_profit": exit_price = take_profit

                    pnl_ratio = (exit_price / entry_price) if position == 1 else (entry_price / exit_price)
                    equity *= pnl_ratio * (1 - self.fee) ** 2
                    position = 0

            # --- –õ–æ–≥–∏–∫–∞ –≤—Ö–æ–¥–∞ ---
            if position == 0:
                signal = int(df['prediction'].iloc[i - 1])
                if signal != 0:
                    entry_price = current_open
                    entry_bar_index = i
                    position = signal
                    self.trades.append(i)

                    volume_spike = df['volume_spike_ratio'].iloc[i - 1]
                    base_rr = strategy_params.get('base_rr', 1.5)
                    volume_multiplier = strategy_params.get('volume_multiplier', 0.5)
                    dynamic_rr = min(base_rr + (volume_spike * volume_multiplier), 8.0)

                    stop_loss_price = df['low'].iloc[i - 1] if signal == 1 else df['high'].iloc[i - 1]
                    risk_per_share = abs(entry_price - stop_loss_price)

                    take_profit_amount = risk_per_share * dynamic_rr
                    take_profit = entry_price + take_profit_amount if signal == 1 else entry_price - take_profit_amount
                    stop_loss = stop_loss_price

            equity_history[i] = equity

        # --- –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ---
        equity_series = pd.Series(equity_history, index=df.index)
        stats = self.calculate_performance(equity_series)
        stats.update({"–í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫": len(self.trades)})
        self.trades = []
        return stats

